[00:23:26] *** Quits: bluss (bluss@moz-ec5o68.cust.bredbandsbolaget.se) (Ping timeout: 121 seconds)
[01:49:55] *** Quits: mcpherrin (mcpherrin@moz-fl0kt2.ca.comcast.net) (Ping timeout: 121 seconds)
[01:50:52] *** Joins: c74d3 (c74d3a4ebb6@moz-l85t2q.mggc.hibn.4404.2002.IP)
[01:52:21] *** Quits: c74d (c74d3a4ebb6@moz-0ersgu.oc.cox.net) (Ping timeout: 121 seconds)
[01:52:31] *** c74d3 is now known as c74d
[01:56:34] *** Quits: c74d (c74d3a4ebb6@moz-l85t2q.mggc.hibn.4404.2002.IP) (Connection closed)
[01:56:59] *** Joins: c74d (c74d3a4ebb6@moz-gadv8g.mggc.hibn.4404.2002.IP)
[05:42:46] *** Quits: Tobba (Tobba@moz-o13d22.bredband.telia.com) (Ping timeout: 121 seconds)
[05:51:00] *** Quits: c74d (c74d3a4ebb6@moz-gadv8g.mggc.hibn.4404.2002.IP) (Connection closed)
[05:51:15] *** Joins: c74d (c74d3a4ebb6@moz-0ersgu.oc.cox.net)
[06:47:38] *** Joins: Tobba (Tobba@moz-6oh.7ki.21.217.IP)
[06:54:44] *** Joins: bluss (bluss@moz-ec5o68.cust.bredbandsbolaget.se)
[07:39:49] *** Quits: Tobba (Tobba@moz-6oh.7ki.21.217.IP) (Ping timeout: 121 seconds)
[07:50:08] *** Joins: Tobba (Tobba@moz-6oh.7ki.21.217.IP)
[09:23:06] *** Joins: gleb (gleb@moz-3u1drv.rusanovka-net.kiev.ua)
[09:40:08] *** Quits: Tobba (Tobba@moz-6oh.7ki.21.217.IP) (Ping timeout: 121 seconds)
[10:20:08] *** Joins: Tobba (Tobba@moz-6oh.7ki.21.217.IP)
[10:42:30] *** Quits: Tobba (Tobba@moz-6oh.7ki.21.217.IP) (Ping timeout: 121 seconds)
[11:18:25] *** Joins: Tobba (Tobba@moz-6oh.7ki.21.217.IP)
[12:05:24] *** Quits: Tobba (Tobba@moz-6oh.7ki.21.217.IP) (Ping timeout: 121 seconds)
[12:08:41] *** Joins: Tobba (Tobba@moz-6oh.7ki.21.217.IP)
[12:22:40] *** Quits: Tobba (Tobba@moz-6oh.7ki.21.217.IP) (Ping timeout: 121 seconds)
[12:23:38] *** Quits: vadimcn (uid46608@moz-0d43u8.highgate.irccloud.com) (Quit: Connection closed for inactivity)
[12:24:37] *** Joins: Tobba (Tobba@moz-6oh.7ki.21.217.IP)
[12:59:00] *** Quits: Tobba (Tobba@moz-6oh.7ki.21.217.IP) (Ping timeout: 121 seconds)
[14:10:09] *** Joins: Tobba (Tobba@moz-o13d22.bredband.telia.com)
[16:04:13] *** Joins: vadimcn (uid46608@moz-0d43u8.highgate.irccloud.com)
[16:16:16] *** Quits: gleb (gleb@moz-3u1drv.rusanovka-net.kiev.ua) (Ping timeout: 121 seconds)
[17:04:59] *** Joins: brson (brson@moz-cfhap5.mtv2.mozilla.com)
[17:04:59] *** ChanServ sets mode: +ao brson brson
[17:31:38] <edunham> brson, acrichto would it interfere with your workflow if I update the bastion then reboot it today? I'm thinking noon for the reboot if that's when you grab lunch :)
[17:32:50] <acrichto> edunham: I don't think I've ever restarted the bastion before... I think it may disconnect community slaves for a bit? that may not be so bad though
[17:32:57] <acrichto> edunham: regardless though it wouldn't interrupt my workflow :)
[17:34:48] <edunham> are there docs somewhere on how the bastion interacts with community slaves?
[17:40:54] * edunham googles and finds https://internals.rust-lang.org/t/community-supported-build-slaves-for-2nd-tier-platforms/1528/4 and https://github.com/rust-lang/rust-buildbot/issues/2
[17:40:55] <brson> edunham acrichto: it should not affect the slaves. they go through the build master directly
[17:41:12] <brson> edunham: you might snapshot an ami from the bastion
[17:41:16] <brson> edunham: why the reboot?
[17:41:52] <edunham> brson: the *** /dev/xvda1 should be checked for errors ***
[17:42:49] <brson> ah
[17:42:50] <edunham> in the MOTD annoys me, and it means the root volume thinks it needs to be fscked
[17:43:49] <edunham> it seems to be a pretty common problem, and setting FSCKFIX in rcS then touching /forcefsck and rebooting are the standard answer
[17:44:01] <edunham> (from both ubuntu and aws docs)
[19:41:40] *** Joins: nrc (nrc@moz-14pjgj.xtra.co.nz)
[19:41:40] *** ChanServ sets mode: +ao nrc nrc
[19:58:06] <edunham> well, that was naive of me, to think the meeting would be done by noon
[20:02:22] <edunham> brson, acrichto I'm going to assume you've escaped from the meeting and fled to lunch, and reboot it now. I've set it to force fsck and fix anything it finds, so it'll be slower than a regular reboot.
[20:02:52] <brson> edunham: sgtm
[20:03:42] *** Joins: xilec (Mibbit@moz-g6k.oht.161.46.IP)
[20:11:39] <edunham> ok, annoying motd message is gone. TIL that touching /forcefsck only makes it actually fsck if you reboot from the AWS console, not from the command line.
[20:22:30] <acrichto> edunham: wfm!
[20:23:04] <edunham> yep, all done with maintenance for now
[20:23:56] <edunham> also turns out that AWS monitoring has a free tier. I should play with that... worst case, it's annoying and spammy and I turn it off again. http://aws.amazon.com/cloudwatch/pricing/
[20:29:16] <acrichto> edunham: whoa I had no idea that was a thing
[20:29:27] <acrichto> edunham: 3.50/month is also dirt cheap
[20:29:40] <acrichto> e.g. $50/month/instance is dirt cheap
[20:29:53] <acrichto> 50 x 12 x 15 == 9000, hm maybe not that dirt cheap
[20:30:11] * edunham looks into what we can do with free tier
[20:30:28] <edunham> hmm looks like there's this alarms system that'll notify arbitrary accounts when metrics hit threshholds
[20:31:16] <edunham> the easy part of monitoring is getting pinged when stuff looks broken; the harder parts are detailed analyses and beautiful graphs and stuff... 
[20:31:48] <acrichto> true
[20:31:53] <acrichto> although getting pinged is a good start lol
[20:32:05] <edunham> yeah getting pinged at all is much better than what we have right now
[20:32:56] <edunham> My goal is to start out with threshholds such that I only get notified when something user-facing and very bad happens
[20:33:53] <edunham> leave myself maximum bandwidth to do proactive fixes (like, oh, maybe config management for rust would be a nice start) while still addressing the things that need an immediate reaction
[21:40:56] <acrichto> brson: r? https://github.com/rust-lang/rust/pull/25848/files
[21:51:53] <acrichto> brson: also, out of curiosity, where'd the freebsd slaves come from?
[21:53:08] <brson> acrichto: bstrie tried to get a freebsd person to maintain them, but so far they haven't been very responsive
[21:53:11] <brson> i'm not hopeful
[21:53:19] <acrichto> aww :(
[22:04:53] * edunham saw the whole master/slave mess and resolves to just name stuff leader/follower or boss/minion when rearchitecting
[22:11:46] <steveklabnik> edunham: i really really want that
[22:11:53] <steveklabnik> i actually was talking to buildbot upstream about doing it
[22:12:04] <steveklabnik> but there are 6000 mentions of 'slave' and i had to focus on shipping 1.0 :/
[22:14:03] <edunham> steveklabnik: yeah I'm just going to start naming things leader/follower wherever I have the option, and document where I can't, and be like "it's deprecated and we're waiting for buildbot to fix it"
[22:14:33] <edunham> it'd be awesome if we had alternate terms that were catchy, memorable, and fewer keystrokes, though
[22:15:41] * edunham wonders if good old sed -i 's/master/leader' * with all the different capitalizations and stuff through the buildbot codebase would result in something that compiled and worked correctly
[22:15:46] <edunham> update all the docs too :)
[22:16:38] <edunham> brson: hey, I'm looking at https://github.com/rust-lang/rust/issues/25811 and it looks like a 10-minute fix if there aren't any hidden gotchas. who actually needs ssh access to play.r-l.o and doc.r-l.o, other than us?
[22:17:09] <steveklabnik> edunham: :) yeah, i wondered the same. 
[22:19:24] * edunham wonders whether the buildbot test suite is good enough to define whether a modified version of the code works or not
[22:19:24] <steveklabnik> also a very good point
[22:26:10] <brson> edunham: nobody else needs access to those machines
[22:26:46] <edunham> brson: ok, I couldn't think of why anyone would, but figured it was better to ask :)
[23:04:17] <edunham> .... doc.r-l.o has been up 246 days... "system restart required" indeed
[23:04:45] <cmr> Huh, I always thought doc. was S3.
[23:05:08] <edunham> well, there's a doc in ec2
[23:05:42] <edunham> and its IP in the DNS match its IP in AWS so I'm going to say that's where my browser's getting the pages from
[23:05:45] <edunham> *matches
[23:06:22] <edunham> I might, with some tricky duplication and load balancing and stuff, be able to get it updated and rebooted without downtime
[23:13:14] <acrichto> edunham: oh wow that's impressive!
[23:13:15] <acrichto> kinda
[23:14:46] <edunham> acrichto: nah, just slightly sketchy
[23:15:22] <acrichto> lol
[23:15:27] <edunham> I mean... copy the instance, fix what's broken on the copy, point DNS at the copy while the original is still up, wait till no traffic on the original, and now the copy is the canonical machine
[23:16:03] <edunham> the odds of any users noticing that something's going on are much lower than if we just took downtime for one instance
[23:16:53] <edunham> the *right* way to do all this will be to architect config management and load balancing and stuff, but that takes time
[23:17:18] <edunham> and... on the one hand, the thing is currently capable of not falling over for almost a year...
[23:18:15] <acrichto> edunham: I do have a feeling we'll eventually want some sort of HA/load balancing for doc.rust-lang.org
[23:18:21] <acrichto> edunham: we're starting to funnel more and more through that node
[23:18:26] <acrichto> mostly b/c it's our only SSL endpoint :\
[23:19:05] <edunham> and here I was thinking play.r-l.o was the bad one... 
[23:19:24] <edunham> play's problem is that you can't add ec2 instances to security groups while they're running
[23:19:33] <cmr> Eugh that always bit me hard.
[23:20:34] *** Quits: xilec (Mibbit@moz-g6k.oht.161.46.IP) (Ping timeout: 121 seconds)
[23:21:03] <acrichto> edunham: oh eew
[23:21:13] <acrichto> edunham: play doesn't actually have http requests hit it as well
[23:21:18] <acrichto> it all goes through doc
[23:21:21] <acrichto> and is proxied to play
[23:21:27] <acrichto> e.g. nginx is just running on doc
[23:23:19] <edunham> so, uhh, what's up with play? trying to ssh to ubuntu@<ip> asks for a password, and bastion's bash history only has people netcatting and telnetting to a specific port on it??
[23:23:37] <acrichto> edunham: oh the account is root
[23:23:50] <edunham> oh ok
[23:23:51] <acrichto> or not...
[23:24:05] <acrichto> oh right it is
[23:24:16] <edunham> oh, yay
[23:24:27] <acrichto> edunham: play is arch linux, unlike everything else which is ubuntu
[23:24:32] <edunham> well, it's only 123 days...
[23:24:46] <edunham> uhh ok, why's that?
[23:25:02] <cmr> edunham: at the time it was created, ubuntu did not support cgroups sufficiently for the sandboxing.
[23:25:07] <cmr> I don't know if this has changed.
[23:25:15] <edunham> ok, makes sense.
[23:25:36] <acrichto> edunham: yeah we're using a `playpen` executable (in an arch package I think?) and I'm not sure that's available on ubuntu
[23:25:41] <acrichto> that'd be the only blocker though
[23:25:49] <acrichto> that I know of at least
[23:25:52] <cmr> Yeah it's packaged on arch, but it's not hard to build.
[23:25:59] <cmr> https://github.com/thestinger/playpen
[23:26:56] <edunham> yeah I think it'd be less gross to build one package on Ubuntu than to have a random arch box
[23:44:11] <edunham> so. umm. I probably don't want to hear the answer to this, considering the state of the rest of the hosts, but does anybody update the Arch box on a regular basis?
[23:44:34] <cmr> I think strcat used to...
[23:45:07] <acrichto> edunham: no
