[00:09:24] *** Quits: gsingh93 (gulshan@moz-ln1ktu.st3l.iv8o.0004.2601.IP) (Ping timeout: 121 seconds)
[00:53:44] *** Joins: blank_na1e (blank_name@moz-pah0nm.mi.frontiernet.net)
[00:56:26] *** Quits: blank_name (blank_name@moz-f80.i34.36.50.IP) (Ping timeout: 121 seconds)
[01:15:08] *** Joins: esclear (esclear@moz-djivev.dip0.t-ipconnect.de)
[01:17:48] *** Quits: esclear_ (esclear@moz-v6bkcv.dip0.t-ipconnect.de) (Ping timeout: 121 seconds)
[01:34:24] <Ilari> "Donâ€™t use JSON Web Tokens."
[01:35:18] <Ilari> Ah yeah, ASN.1 does not have unambiguous UTF-8 strings. :->
[01:45:07] *** Quits: ugglan (ugglan@moz-rjubsq.priv.bahnhof.se) (Ping timeout: 121 seconds)
[01:45:40] *** Joins: ugglan (ugglan@moz-rjubsq.priv.bahnhof.se)
[02:08:02] *** Joins: c74d3 (c74d3a4ebb6@moz-rhs0n6.mggc.hibn.4404.2002.IP)
[02:08:34] *** Quits: dpc (dpc@moz-t6gr4b.ca.comcast.net) (Connection closed)
[02:09:26] *** Quits: c74d (c74d3a4ebb6@moz-0ersgu.oc.cox.net) (Ping timeout: 121 seconds)
[02:09:45] *** c74d3 is now known as c74d
[02:10:52] *** Joins: dpc (dpc@moz-t6gr4b.ca.comcast.net)
[02:14:49] *** Joins: Tuba (Tobba@moz-o13d22.bredband.telia.com)
[02:17:09] *** Quits: Tobba (Tobba@moz-o13d22.bredband.telia.com) (Ping timeout: 121 seconds)
[02:17:59] <bascule> Ilari: lol, who said that
[02:18:01] <bascule> I agree with it
[02:18:04] <bascule> cuz, uhh, Macaroons
[02:18:06] <bascule> are sane
[02:18:48] <bascule> Ilari: did you ever read the Zebra Copy paper?
[02:18:51] <bascule> basically, the SAML paper
[02:19:08] <bascule> ignoring the fact that any XML-based format is radioactive plutonium from a LANGSEC perspective
[02:20:03] *** Tuba is now known as Tobba
[02:23:33] <Tobba> does anyone have any recommendations for designing file formats out of a langsec perspective?
[02:23:44] <bascule> tl;dr: context free or regular
[02:25:17] <Tobba> I want to have some components that are reused between formats, so they're easily verified and everything isnt its own special snowflake
[02:25:36] <Tobba> but it seems hard to find anything decent in that area
[02:25:40] <bascule> great! context-free grammars are awesome at that
[02:26:28] <Tobba> yeah I know, I guess there isn't anything existing
[02:26:33] <bascule> see also: ragel
[02:26:34] <bascule> o_O
[02:26:35] <bascule> uhh
[02:26:47] <bascule> yacc and its millions of alikes?
[02:26:53] <bascule> I'm sure there's one for <insert language here>
[02:27:04] <bascule> provided you're cool with LALR
[02:27:28] <bascule> LL* is also well-regarded
[02:28:37] <Tobba> ... I think I've worked on this paper a bit too long, I'm starting to sound liky my own bullshit
[02:30:25] <Tobba> bascule: I'm mostly looking at things like EBML (which might be a nice choice for this)
[02:30:25] *** Joins: atomic (atomic@moz-67r1nt.torservers.net)
[02:30:58] <bascule> "EBML was designed to be a simplified binary extension of XML"
[02:31:01] <bascule> ABORT ABORT ABORT
[02:31:59] <eternaleye> bascule: Context-free isn't even sufficient IMO - I mean, general context-free parsing is O(nÂ³)
[02:32:17] <bascule> eternaleye: I actually like context-sensitive :o
[02:32:18] <bascule> but
[02:32:19] <eternaleye> Earley, &co
[02:32:31] <mcpherrin> bascule: then you have RBML! Really Bad Markup Language (rbml) is an internal serialization format of rustc (and is based on EBML)
[02:32:33] <bascule> for very simple context-sensitive grammars that are easy-to-describe and unambiguous
[02:32:40] <bascule> mcpherrin: oh god
[02:32:42] <eternaleye> bascule: Well, there are subsets more restricted than all of CF that are still nice, without foing all the way down to regular
[02:32:55] <eternaleye> *going
[02:33:08] <bascule> eternaleye: the context-sensitive grammars I like can be described in like... two lines of regular expressions
[02:33:17] <bascule> where the second is paramaterized around the result of the first
[02:33:28] <bascule> and the first looks like [0-9a-f]{4}
[02:33:33] <mcpherrin> RBML variable length integers! Everybody loves them
[02:33:40] <eternaleye> bascule: Recursive-regular is nice
[02:33:46] <bascule> yeah, that's a great term for it
[02:35:46] <Ilari> Deterministic Context-Free... Recdescent-parseable...
[02:36:15] <bascule> it's just so simple you can't fuck it up
[02:36:21] <bascule> even coding it by hand
[02:36:34] <bascule> at least, one would hope
[02:37:04] <bascule> djb did something similar but like, too complicated imo: http://cr.yp.to/proto/netstrings.txt
[02:37:10] <bascule> variable length length prefixes
[02:37:14] <bascule> no thanks
[02:37:15] <eternaleye> bascule: There's also that choosing your languages by your parsers, rather than the other way around, is a viable option
[02:37:26] <eternaleye> bascule: Since the languages are kind of... coarse-grained
[02:37:39] <bascule> eternaleye: nom looks cool ;)
[02:37:43] <eternaleye> bascule: But "unambiguous LL(n)" (for some small fixed n) ain't bad
[02:37:47] <eternaleye> bascule: Yeah, it's awesome
[02:37:53] <eternaleye> bascule: I helped out with the macros :D
[02:37:55] <bascule> nice
[02:38:07] <eternaleye> bascule: closure!(), named!(), and generating thunks rather than functions
[02:38:10] <Ilari> Then there are tokenizable variants of the above (which are in general are context-sensitive).
[02:38:13] <eternaleye> bascule: Those were my big innovations
[02:38:33] <eternaleye> bascule: Oh, also call!(), and the general "parse a macro invocation to reconstruct it with one more parameter" thing
[02:38:40] <bascule> Ilari: have you ever seen the SAML/Zebra Copy paper?
[02:38:44] <bascule> it's kind of horrifying
[02:38:51] <Ilari> I don't think so.
[02:39:12] <bascule> I guess I'm just averse to crazy interaction diagrams for authentication scenarios
[02:39:12] <Tobba> I kinda wish nom operated on any stream, not just byte streams
[02:39:15] <bascule> and SAML is like
[02:39:21] <bascule> we took this zomgwtfbbq interaction
[02:39:29] <bascule> and reduced it to this omgwtfbbq interaction
[02:39:40] <bascule> Ilari: http://www.hpl.hp.com/techreports/2007/HPL-2007-105.pdf
[02:39:43] <eternaleye> A re-implementation of chain!() to not be horrendous and inflexible was actually my first Rust macro :P
[02:40:03] <bascule> Ilari: SAML makes me very sad. JWT makes me ever so slightly less sad.
[02:45:00] <eternaleye> Tobba: The problem with doing an iterator-based version will be in operating on the results.
[02:45:14] <eternaleye> Tobba: Since you'd need to collect(), which copies or moves.
[02:46:41] <Tobba> well there are a few ways around that, but I haven't had time to properly look at how nom operates
[02:51:25] <eternaleye> Tobba: It works on &[u8]
[02:51:46] <eternaleye> Tobba: But not necessarily only one
[02:52:00] <eternaleye> Tobba: Since it supports incremental parsing &c
[02:57:04] <Tobba> I'm more talking about how the results from each parser are handled, but yeah
[03:03:00] <eternaleye> Ah, that's IResult
[03:03:18] <eternaleye> Which an enum of Success, Failure, or Incomplete(usize)
[03:03:18] <cmr> nom looks annoying to use, but I haven't actually tried using it yet.
[03:03:50] <eternaleye> Failure carries the input buffer, IIRC
[03:04:04] <eternaleye> Success carries arbitrary T, and the input buffer minus the matched content
[03:04:16] <eternaleye> cmr: It's actually quite nice
[03:04:44] <eternaleye> cmr: You compose your parser with the macros, run it with Consumer or Producer, and then enjoy the results.
[03:05:04] <cmr> I don't think it had macros when I looked at it...
[03:05:19] <eternaleye> cmr: Wow, that must have been quite a while ago...
[03:05:29] <cmr> yeah, ~when it was first announced
[03:05:29] <eternaleye> cmr: They're pretty central
[03:05:36] <eternaleye> cmr: No, it had macros then
[03:05:53] <eternaleye> cmr: tag!("literal"), and chain!(rule, otherrule), and so forth
[03:05:59] <eternaleye> cmr: Though they have changed a good bit
[03:06:21] <cmr> hm, perhaps it was a different parser combinator library then!
[03:06:28] <cmr> looking at the readme, nom looks very nice.
[03:06:37] <eternaleye> cmr: (that announcement was what got me interested, and then I prodded geal on #rust and hammered out some changes to them)
[03:07:38] <eternaleye> Just tossing things up on playrust and showing how nice they could wind up, him making some changes and tossing it back, until we got something nice and he committed it
[03:16:23] *** Quits: Tobba (Tobba@moz-o13d22.bredband.telia.com) (Ping timeout: 121 seconds)
[03:35:57] <Ilari> bascule: Regarding TLS, the only place where "large" messages could be a problem is Client Certificate Verify in TLS 1.2.
[03:41:07] <bascule> Ilari: I might be a bit biased because we design our own SoCs, heh
[03:41:12] <bascule> our devices are tiny but not that tiny
[03:41:31] <bascule> our EMV reader has a CPU with equivalent power to a first generation iPhone
[03:41:43] <mcpherrin> bascule: woah
[03:42:03] <mcpherrin> bascule: I had been assuming you had much smaller mcus in those things
[03:42:11] <bascule> mcpherrin: not in the EMV reader
[03:42:15] <bascule> see also: https://squareup.com/news/square-acquires-kili
[03:43:35] <bascule> to paraphrase that post, Kili designed an SoC that does EMV/NFC
[03:43:47] <bascule> one chip to do it all
[03:43:49] <bascule> pretty snazzy
[03:44:42] <mcpherrin> schmazzy indeed
[03:45:08] <bascule> mcpherrin: our standard reader has a much tinier MCU, yes
[03:45:13] <bascule> "standard"
[03:45:14] <bascule> dying standard
[03:45:27] <bascule> as you might guess from our CTF, it's MSP430-based
[03:45:35] <bascule> but that thing sure as hell isn't speaking TLS, heh
[03:45:39] <bascule> much less doing anything pubkey
[03:46:03] <Ilari> bascule: There the message size could be 8kB or so...
[03:46:17] <mcpherrin> per-device secret key burned in at manufacture time with a dedicated AES hardware I'd assume
[03:46:37] <bascule> yes, also an odd mode of operation whose name I always have to look up
[03:46:53] <bascule> CCFB mode
[03:46:54] <mcpherrin> MCU and a DSP to read data, encrypt, then write over the headphone jack
[03:47:00] <bascule> https://www.iacr.org/archive/fse2005/35570282/35570282.pdf
[03:47:03] <bascule> the paper hurts my eyes
[03:47:16] <bascule> it's like it got wet or something
[03:47:19] <bascule> but it's digital
[03:47:19] <bascule> wat
[03:47:51] <mcpherrin> I feel like I recognize those artifacts
[03:47:53] <cmr> it looks fine to me?
[03:48:36] <mcpherrin> I think it's latex -> postscript -> pdf 
[03:48:40] <bascule> cmr: you don't see the letters at random odd heights and all truncated?
[03:48:56] <cmr> no.
[03:49:11] <bascule> https://i.imgur.com/4uITwDj.png
[03:49:14] <bascule> that's how it renders for me
[03:49:23] <bascule> it's just subtly fucked
[03:49:28] <mcpherrin> bascule: woah, definitely renders better than that for me.  What viewer are you using?
[03:49:32] <bascule> maybe I like typography too much
[03:49:36] <bascule> mcpherrin: Apple preview
[03:49:42] <mcpherrin> .. me too?
[03:49:45] <bascule> lol weird
[03:50:05] <bascule> it looks different from that?
[03:50:09] <cmr> http://i.imgur.com/PLz7XPs.png for me.
[03:50:20] <cmr> pdf.js
[03:50:29] <bascule> that still looks subtly fucked to me, heh... but much better
[03:50:31] <mcpherrin> https://imgur.com/7AzSLRh
[03:50:51] <bascule> mcpherrin: that part of the page looks better
[03:51:02] <cmr> I dunno looks like stock pdflatex to me.
[03:51:30] <mcpherrin> bascule: looks fine on OS X 10.9 preview on a retina mbp (13", late 2013)
[03:51:40] <bascule> this is how Chrome renders it: https://i.imgur.com/KmGkpAC.png
[03:51:43] <bascule> lolololololol
[03:51:46] <cmr> lol that's so bad
[03:51:55] <mcpherrin> wow, that's comically bad
[03:52:14] <mcpherrin> bascule: You sure you don't have prank malware installed? haha.
[03:52:19] <mcpherrin> (because that would be some fine prank malware)
[03:52:23] <bascule> haha uhh I hope I don't have malware
[03:53:40] *** Quits: dpc (dpc@moz-t6gr4b.ca.comcast.net) (Ping timeout: 121 seconds)
[03:53:49] *** Quits: dpc_ (dpc@moz-t6gr4b.ca.comcast.net) (Ping timeout: 121 seconds)
[04:08:10] <Ilari> bascule: Server Certificate Verify in TLS 1.2 is ~1kB at worst (typically much less), TLS 1.3 Certificate Verifys are like 150 bytes at worst.
[04:16:12] *** Joins: gsingh93 (gulshan@moz-ln1ktu.st3l.iv8o.0004.2601.IP)
[04:22:05] <Ilari> "Note that this requires both sides to either buffer the messages or compute running hashes for all potential hash algorithms up to the time of the CertificateVerify computation."
[04:22:10] <Ilari> "Servers can minimize this computation cost by offering a restricted set of digest algorithms in the CertificateRequest message."
[04:30:53] <Ilari> Also, CCV covers for most of the handshake, where SCV only covers one message sent by server (in TLS 1.2). In TLS 1.3, both only cover one (implicit) message.
[05:07:20] <bascule> Ilari: heh: https://twitter.com/sleevi_/status/604140507044827136
[05:07:37] <bascule> Ilari: is this all much ado about nothing?
[05:07:42] <bascule> re: 1kB
[05:07:46] <bascule> lol
[05:13:38] *** Joins: c74d3 (c74d3a4ebb6@moz-0ersgu.oc.cox.net)
[05:14:46] *** Quits: c74d (c74d3a4ebb6@moz-rhs0n6.mggc.hibn.4404.2002.IP) (Ping timeout: 121 seconds)
[05:15:22] *** c74d3 is now known as c74d
[05:41:26] <eternaleye> bascule: cmr: Poppler-based stuff does alternating smooshed/normal characters in the abstract, but the rest of the paper is fine
[05:41:39] <eternaleye> bascule: cmr: And yes, that's usually on tex -> ps -> pdf
[05:41:55] <cmr> Interesting. I have noticed the artifact in evince before.
[05:41:58] <eternaleye> bascule: cmr: Modern pdftex/xelatex seems to avoid the issue
[05:42:03] <eternaleye> cmr: evince uses poppler
[05:42:05] <cmr> (which is popler based)
[05:42:27] <eternaleye> Poppler's pretty much That PDF Library on Linux
[05:43:20] <eternaleye> Anyway, what it probably comes down to is some variety of rounding issue.
[05:43:39] <eternaleye> Since it seems to only occur on downscaled text
[05:44:53] <eternaleye> bascule: Actually, that probably does make typesetting LaTeX properly easier :P
[05:44:56] <Ilari> BTW, Root level address records are not allowed for gTLDs.
[05:45:09] <eternaleye> bascule: Just put "LATEX" in a PDF, and bam! Properly typeset!
[05:45:15] <eternaleye> bascule: :P
[05:46:34] <Ilari> bascule: And it is not just 1kB. It is also duraition of the data (short).
[05:46:37] <eternaleye> I wonder how useful it'd be to have hashes/MACs whose state object implements Clone, so you can fork a running hash for partial input...
[05:46:51] <bascule> remember dvips
[05:46:52] <bascule> lol
[05:46:57] <eternaleye> bascule: ohgod
[05:47:07] <eternaleye> bascule: I actually still have a textbook in dvi
[05:47:08] <bascule> or LyX
[05:47:09] <bascule> lololol
[05:47:22] <eternaleye> bascule: I mean, not for anything I'm doing now
[05:47:28] <eternaleye> bascule: But I still _have_ it
[05:47:34] <bascule> I guess LyX is still around and maintained
[05:47:41] <bascule> I haven't used it for like 15 years at least?
[05:47:44] <eternaleye> bascule: Because if the internet had a version of the Hoarders show, I'd be subject #1
[05:48:05] <eternaleye> My _laptop_ has a 2tb drive.
[05:48:07] <eternaleye> It's full.
[05:48:12] <cmr> O_o
[05:48:29] <cmr> I'm sure bitsavers or archive.org would be subject #1 :P
[05:48:36] <eternaleye> And I will probably put a second one in the other bay when I can afford it.
[05:48:51] <eternaleye> cmr: Nah, organizations aren't hoarders, they're historical societies!
[05:49:00] <cmr> Pft, anyone can found an organization.
[05:49:01] <eternaleye> cmr: Just like rich people aren't crazy, they're eccentric!
[05:49:23] <eternaleye> cmr: Also, they've got some variety of _goal_
[05:49:34] <eternaleye> cmr: I just get things, and then never wind up throwing them away
[05:49:44] *** Quits: gsingh93 (gulshan@moz-ln1ktu.st3l.iv8o.0004.2601.IP) (Ping timeout: 121 seconds)
[06:06:23] <Ilari> bascule: Apparently as background, the cert is rejected by Firefox. :-)
[06:27:00] <bascule> yup
[06:27:04] <bascule> hence the drama
[07:25:00] *** Joins: Tobba (Tobba@moz-6oh.7ki.21.217.IP)
[07:45:02] *** Quits: irobevjodu (ident@moz-mikldi.static-ro.twistednetworks.net) (Connection closed)
[08:03:06] *** Joins: irobevjodu (ident@moz-f72.9jj.82.80.IP)
[08:34:23] *** Quits: irobevjodu (ident@moz-f72.9jj.82.80.IP) (Ping timeout: 121 seconds)
[10:25:00] *** Joins: gleb (gleb@moz-3u1drv.rusanovka-net.kiev.ua)
[12:19:05] *** Quits: Tobba (Tobba@moz-6oh.7ki.21.217.IP) (Ping timeout: 121 seconds)
[13:25:43] *** Joins: Tobba (Tobba@moz-o13d22.bredband.telia.com)
[13:48:00] *** Joins: irobevjodu (ident@moz-mikldi.static-ro.twistednetworks.net)
[15:19:56] *** Joins: gsingh93 (gulshan@moz-ln1ktu.st3l.iv8o.0004.2601.IP)
[15:24:55] *** Quits: gleb (gleb@moz-3u1drv.rusanovka-net.kiev.ua) (Ping timeout: 121 seconds)
[15:34:58] <kmc> eternaleye: donate your hard drive to the internet archive
[16:34:29] *** Quits: eternaleye (eternaleye@moz-7ps.ehi.245.50.IP) (Ping timeout: 121 seconds)
[16:38:51] *** Joins: eternaleye (eternaleye@moz-7ps.ehi.245.50.IP)
[17:42:22] *** Joins: dpc (dpc@moz-t6gr4b.ca.comcast.net)
[17:42:31] *** Joins: dpc_ (dpc@moz-t6gr4b.ca.comcast.net)
[17:52:02] <eternaleye> kmc: but I still need it!
[17:52:20] <eternaleye> kmc: (partially because unless I'm at work, my only source of internet is phone tethering)
[18:10:40] <bascule>  13_4__8__ 9_11__12_  13_4__ 8_9__11_    13_ 4_8_   11__12_ 13_ 4_ 
[18:10:43] <bascule> 4|  8_9__11|  12_ 13\4|_ 8_9|  11_ 12\  4/ 8\\ 9\ 11/ 12/ 13| 4| 8|
[18:10:46] <bascule> 8| 9|_  12| 13|_4) 8|| 9|11| 12| 13| 4|/ 8_ 9\11\ 12V 13/| 4| 8| 9|
[18:10:49] <bascule> 9|  11_12| 13|  4_ 8< 9| 11|12| 13|_4| 8/ 9__11_ 12\| 13| 4|8_|9_|11_|
[18:10:52] <bascule> 11|_12|   4|_8| 9\_11\_12__13|_4__8_/9_/   12\13_\4_| 8(9_|11_|12_)
[18:10:55] <cmr> c-c-c-c-c-combo breaker
[18:10:55] <bascule>                                         
[18:10:57] <cmr> dammit too slow
[18:15:43] <eternaleye> cmr: You should set it as a trigger on the first line :P
[18:16:56] <bascule> lol
[18:35:00] <Ilari> Heh... Digitally signing machine config data.
[18:49:41] <kmc> intel microcode updates are digitally signed
[18:50:05] <kmc> the processor has a (probably slow) implementation of RSA on-board to check them
[18:50:05] <Ilari> Also encrypted.
[18:50:22] <bascule> how about that TrustZone? lol
[18:50:45] <kmc> which means someone had to implement modular bignum arithmetic in micro-ops
[18:50:48] <bascule> building teetering towers of multi-stage secure boot
[18:50:50] <kmc> lol
[18:50:56] <bascule> kmc: sounds super fun!
[18:50:57] <kmc> Pizza Zone
[18:53:55] *** Quits: gsingh93 (gulshan@moz-ln1ktu.st3l.iv8o.0004.2601.IP) (Ping timeout: 121 seconds)
[18:53:58] <bascule> either of you see the TrustZone integer overflow -> RCE thing from BlackHat last year?
[18:54:16] <bascule> I don't get why the TrustZone kernels are so complicated o_O
[18:54:34] <bascule> when people talk about a Rust OS, maybe they should be targeting that space instead of, say, a better Linux
[19:03:50] <bascule> Ilari: does your ECC lib expose a generic scalar multiplication API I could use with e.g. Ed25519?
[19:03:59] <bascule> and if so, you should open source it already! lol
[19:04:42] <bascule> I want to implement this: https://gist.github.com/tarcieri/4760215
[19:11:42] <Ilari> bascule: You mean like: pub fn mul_s(&mut self, a: &Scalar, b: &Point) -> Result<(), Error>
[19:12:00] <bascule> yes!
[19:17:01] <Ilari> Thanks to lack of dependent associated constants, the code is total mess.
[19:22:35] <Ilari> I consider the C++ template mess required to do similar things as less messy...
[19:37:12] <posix4e> bascule: interesting thesis, i have been looking at rump kernel stuff with rust
[19:37:24] <posix4e> I kinda feel like kernel's in general are a crutch, we didn't need them back in the day
[19:38:13] <Ilari> Well, isn't the task of kernel to multiplex and control access to various resources?
[19:40:03] <posix4e> Yea, who needs it
[19:40:22] <posix4e> i mean for desktop for sure
[19:40:38] <cmr> Even on desktop surely you want multiple applications able to use the GPU at once.
[19:40:42] <posix4e> but with virtualization and stuff now...
[19:40:43] <cmr> Or the soudn card.
[19:40:59] <posix4e> for sound card certainly not
[19:41:00] <posix4e> but graphics yea
[19:41:28] <posix4e> desktops and mobile i can see operating systems having a role a bit longer
[19:41:36] <Ilari> Virtualization usually deals just with memory, CPU and networking, and things like that.
[19:41:37] <posix4e> but in general i see a lot of this moving into hardware
[19:41:54] <posix4e> llari: have you been following the research into unikernels?
[19:42:07] <posix4e> Or contemporary performance stuff like userland networking?
[19:42:14] <cmr> IBM's been doing it since the 70s.
[19:42:26] <Ilari> posix4e: Well, I have heard of microkernels and nanokernels.
[19:43:00] <posix4e> no, nothing since that
[19:43:04] <posix4e> cmr: 70s longer than that
[19:43:10] <posix4e> cmr: that's how it always worked back in the day
[19:43:34] <posix4e> Anyway sorry for the noise. Enjoy!
[19:43:40] <cmr> posix4e: No, I mean a lightweight hypervisor multiplexing applications.
[19:43:56] <cmr> Not home-PC style single-applications.
[19:44:06] <posix4e> Yea that's how mainframes basically always worked
[19:44:38] <posix4e> I mean, i was born in 81, I don't have a lot of experience with mainframes but os/360 is from 1966
[19:46:15] <Tiffany> unikernels are never going to reach widespread use
[19:46:28] <Tiffany> nobody wants to download a 4 gigabyte OS image so they can run an irc client
[19:46:44] <Tiffany> there's also some major assumptions that any resource can be sufficiently multiplexed
[19:46:44] <posix4e> I don't think unikernels are targetting desktop and mobile
[19:46:49] <Tiffany> who does the GPU if every application is a unikernel?
[19:46:52] <posix4e> Why do keep on bring it back to that
[19:46:52] <Tiffany> er, GUI*
[19:47:19] <posix4e> It's a straw man
[19:47:55] <Tiffany> you're the one who brought it up when bascule was talking about x86, not a specific usage of x86
[19:48:29] <posix4e> sorry i don't mean to be rude, but I thought i said it twice already
[19:48:47] <Tiffany> what do unikernels have to do with trustzone?
[19:49:02] <Tiffany> oh, rust OS
[19:49:14] <Tiffany> I could see someone creating something akin to mirageOS, but for rust
[19:54:03] <eternaleye> Personally, I think the benefit of Rust isn't in unikernel vs. microkernel vs. macrokernel, but in being able to shade between them dynamically.
[19:55:02] <eternaleye> In particular, an seL4-like messaging system can be made absurdly efficient in a single address space, while still having the same programmer-level API across address spaces
[19:55:09] <eternaleye> Allowing someone to _design_ for microkernel, and at build-time put arbitrary additional components into the core set.
[19:55:36] <eternaleye> Shading from microkernel to macrokernel to unikernel as they see fit, with arbitrary granularity.
[19:56:12] <eternaleye> (Possibly even at runtime, if they pick a sufficiently shiny task-spawning API)
[19:57:23] <eternaleye> It's part of why I'm focusing on designing my OS around spawning being the _only_ source of asynchrony, and all calls are either nonblocking-on-failure, or wait-for-success, with timeslice-delegation.
[20:00:23] <Tiffany> I was thinking about this in my own ideas about building an OS
[20:01:44] <Tiffany> it mostly made me kind of upset that context switches are so slow
[20:01:50] <eternaleye> Incidentally, queued locks have a really nice set of behaviors when it comes to that kind of thing, because then you get nice first-come-first-served behavior from senders, with timely service to boot
[20:01:59] <Tiffany> I want the mill to swoop in and save me from having to decide
[20:02:28] <eternaleye> Tiffany: Context switches don't have to be slow, though?
[20:02:37] <eternaleye> Tiffany: The seL4 paper is pretty clear on that
[20:02:49] <Tiffany> they're faster under seL4 than linux for sure
[20:02:56] <Tiffany> but they're still much slower than a function call
[20:03:47] <eternaleye> Tiffany: Sure, but that just means you shouldn't be super-free with them
[20:03:55] <eternaleye> Tiffany: However, there are all sorts of ways to handle that
[20:04:18] <eternaleye> Tiffany: For example, in some cases it might be fine to batch calls (vector instruction style)
[20:04:37] <Tiffany> how fast are context switches in seL4 specifically, actually?
[20:04:46] <eternaleye> Tiffany: Digging up the paper now
[20:05:46] <eternaleye> IIRC, it was a summary paper the seL4 team did about the L4 family over time
[20:06:07] <eternaleye> Aha! http://flint.cs.yale.edu/cs428/doc/L3toseL4.pdf
[20:06:30] <eternaleye> Tiffany: p3 has the one-way IPC cost on various architectures
[20:06:45] <eternaleye> Tiffany: Which is pretty much exactly "one-way context switch between processes"
[20:07:01] <Tiffany> ooh, 300 cycles
[20:07:09] <Tiffany> that's faster than I was expecting
[20:07:10] <eternaleye> Tiffany: Yup.
[20:07:28] <eternaleye> 0.09Âµs
[20:07:31] <Tiffany> well, that decides it then, I don't need to worry about IPC cost
[20:07:36] <Tiffany> on seL4, anyway
[20:07:41] <eternaleye> Itanic was weirdly fast
[20:07:51] <Tiffany> yeah that is strange
[20:07:56] <Tiffany> I would have thought it'd be horrifically slow
[20:08:04] <Tiffany> seeing how there's 300 registers that you either need to save or discard
[20:08:18] <Tiffany> it probably discards most of them
[20:08:22] <eternaleye> Tiffany: I don't think so
[20:08:28] <eternaleye> Tiffany: Wasn't it banked?
[20:08:35] <eternaleye> Tiffany: So it could just shift the window?
[20:08:48] *** Joins: gleb (gleb@moz-3u1drv.rusanovka-net.kiev.ua)
[20:08:52] <Tiffany> I don't know
[20:09:00] <Tiffany> that would certainly explain it
[20:09:11] <Tiffany> the mill does something very similar, and the mill admits to being inspired by itanium
[20:09:16] <Tiffany> what actually went wrong with itanium?
[20:09:24] <Tiffany> I know compiler support was an issue
[20:09:32] <Ilari> Tiffany: And also, it is not x86. :-/
[20:09:49] <Tiffany> that's it?
[20:09:50] <eternaleye> Well, it could run x86 code, but at a horrendous performance penalty
[20:09:55] <Tiffany> I thought it had some fatal design flaw
[20:10:06] <eternaleye> Tiffany: Well, the compiler thing could be viewed as such
[20:10:18] <Tiffany> I remember that it was complicated to build a compiler for it
[20:10:21] <eternaleye> Tiffany: In the same vein as various languages appeals to a "sufficiently advanced compiler"
[20:10:27] <Tiffany> yeah
[20:10:39] <Tiffany> the itanium relied on compiler for performance, but it didn't make the job easy
[20:10:53] <eternaleye> Tiffany: It relied on a Sufficiently Advanced Compiler because it did _zero_ hardware-based OoO etc.
[20:11:00] <Tiffany> the mill intends to rely on the compiler, by exposing things in a way that compilers like
[20:11:08] <Tiffany> hm
[20:11:14] <Tiffany> isn't that just an instruction scheduling problem though?
[20:11:53] <Ilari> Also, doing nothing advanced and relying on SAC seems like compat hazard...
[20:11:54] <eternaleye> Tiffany: Itanium was basically good at the same kind of code GPUs are good for, IIUC - few, predictable branches, etc.
[20:12:29] <Tiffany> that sounds like a stretch
[20:13:08] <Tiffany> did the itanium have a really long pipeline, then?
[20:13:19] <Tiffany> that was something that everyone groaned at in the pentium series
[20:13:23] <posix4e> Tiffany: I used a lot of itanium
[20:13:28] <posix4e> the people who used it came from alpha
[20:13:47] <posix4e> 4 years after the last alpha chips we started to see itanic
[20:13:54] <posix4e> they were barely faster
[20:14:09] <posix4e> So people were all like "what's the point"
[20:14:42] <eternaleye> Tiffany: Static instruction scheduling doesn't (in my understanding) cope well with branches that are not readily amenable to static prediction.
[20:15:03] <Tiffany> oh
[20:15:04] <Tiffany> I see
[20:15:22] <Ilari> Also, how big is the per-thread performance gap between amd64 and non-x86 nowadays?
[20:15:30] <Tiffany> so x86 can do some things if it gets stuck in a branch miss
[20:15:53] <Tiffany> I imagine it depends on what code you're running, ilari
[20:15:53] <posix4e> llari: amd has mostly caught up 
[20:15:57] <posix4e> the next release will close the gap
[20:16:08] <Tiffany> you misread, posix4e
[20:16:10] <posix4e> the fact that the smt patent is up will play a big deal
[20:16:18] <posix4e> ooh 
[20:16:20] <posix4e> per thread...
[20:16:33] <posix4e> no idea
[20:16:38] <Tiffany> 64-bit x86 versus everything else
[20:16:45] <eternaleye> Tiffany: Isn't POWER still kind of king at single-thread, it's just impossible to get your hands on?
[20:16:57] <Tiffany> uhh
[20:17:03] <Tiffany> you mean like those IBM mainframes running at 5GHz?
[20:17:05] <posix4e> ah yes, amd64 vs arm and power
[20:17:19] <Tiffany> I actually don't know much about those
[20:17:41] <Tiffany> however, I imagine that if your code is amenable to it, the best perf you can get will be had in high-end DSPs
[20:19:06] <posix4e> or something with adapteva
[20:19:16] <eternaleye> Tiffany: Ah, it seems Haswell actually beats POWER8: http://www.anandtech.com/show/9193/the-xeon-e78800-v3-review/11
[20:19:17] <posix4e> which is kinda like a dsp
[20:19:30] <eternaleye> Tiffany: *however*, it seems to scale dramatically better with increased threads
[20:19:33] <Tiffany> er.. you mean those 64-core boards?
[20:19:35] <posix4e> eternaleye: Yea haswell can do that turbo mode thing
[20:19:41] <posix4e> Tiffany: ya
[20:19:48] <eternaleye> Tiffany: Likely due to the weaker memory model making cache coherency less of a perf drain
[20:19:53] <eternaleye> posix4e: I don't think that's it.
[20:19:55] <Tiffany> ilari asked about per-thread performance though
[20:20:01] <Tiffany> if you're doing raw perf, GPUs always win
[20:20:03] <posix4e> ahh yea
[20:20:20] <Tiffany> also, as for the parallella boards which adapteva has actually shipped
[20:20:23] <Tiffany> most of them are pretty dinky
[20:20:34] <eternaleye> Tiffany: Sure, but "raw perf" and "raw perf with the C programming model" are different things.
[20:20:40] <Tiffany> 19 cores for $99
[20:20:43] <Tiffany> 18*
[20:20:50] <eternaleye> Tiffany: 8 cores? doable with pthreads.
[20:20:51] <eternaleye> Tiffany: GPU? Not so much.
[20:20:59] <Tiffany> yeah
[20:21:17] <eternaleye> Tiffany: And an 8-core POWER8 beats an 8-core Haswell, which is fascinating when it's the other way around for one thread.
[20:21:33] <eternaleye> Tiffany: Oh, wait, no
[20:21:37] <Tiffany> so adapteva teased up to 4096 cores
[20:21:38] <eternaleye> I misread their graph
[20:21:48] <Tiffany> although on their site the highest it goes is 64
[20:21:59] <eternaleye> Oh, wait
[20:22:04] <eternaleye> It's not 8 cores
[20:22:07] <eternaleye> It's 8t/c
[20:22:16] <eternaleye> As in, 8-way SMT
[20:22:17] <Tiffany> let's see how green arrays are
[20:22:28] <eternaleye> That's an _entirely_ different beast.
[20:22:30] <Ilari> On x86 vs. ARM, the lowest figure reported for Curve25519 on amd64 in ebats is 161648. For ARM it is 315284 (but I note that there doesn't seem to be ARM64 systems there)...
[20:22:43] <eternaleye> IOW, Power8 has ridiculously good hyperthreading.
[20:23:11] <eternaleye> Tiffany: So yeah, this benchmark is weird...
[20:23:14] <posix4e> I've actually seen people using gren arrays, but nothing new in years right?
[20:23:23] <posix4e> I knew someone who built a mill controlled by one
[20:23:27] <posix4e> programmed in forth
[20:23:37] <eternaleye> Tiffany: It almost seems like POWER's bottlenecked by instruction decode, or a weak OoO implementation, or something
[20:23:47] <eternaleye> Tiffany: While the backend execution engine is omglol
[20:24:17] <eternaleye> Tiffany: So when it runs eight threads on one core with SMT, it beats the crap out of Haswell running two threads on one core with SMT
[21:33:55] *** Quits: atomic (atomic@moz-67r1nt.torservers.net) (Ping timeout: 121 seconds)
[22:02:47] *** Joins: atomic (atomic@moz-vo7ult.telostor.ca)
[22:48:12] * Ilari stops reading PKIX specs before he gets a headache...
[23:21:53] *** Quits: gleb (gleb@moz-3u1drv.rusanovka-net.kiev.ua) (Ping timeout: 121 seconds)
[23:46:38] *** Quits: dpc_ (dpc@moz-t6gr4b.ca.comcast.net) (Quit: Leaving)
