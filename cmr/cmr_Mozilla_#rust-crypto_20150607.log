[01:04:35] *** Joins: esclear_ (esclear@moz-nq303o.dip0.t-ipconnect.de)
[01:07:15] *** Quits: esclear (esclear@moz-h4andp.dip0.t-ipconnect.de) (Ping timeout: 121 seconds)
[01:49:39] *** Quits: c74d (c74d3a4ebb6@moz-0ersgu.oc.cox.net) (Connection closed)
[01:50:36] *** Joins: c74d (c74d3a4ebb6@moz-0ersgu.oc.cox.net)
[02:25:13] *** Joins: c74d3 (c74d3a4ebb6@moz-3tkm7g.mggc.hibn.4404.2002.IP)
[02:26:29] *** Quits: c74d (c74d3a4ebb6@moz-0ersgu.oc.cox.net) (Ping timeout: 121 seconds)
[02:27:09] *** c74d3 is now known as c74d
[02:27:12] *** Joins: skeuomorf (skeuomorf@moz-d3l.n1e.32.197.IP)
[02:59:34] *** Quits: Tobba (Tobba@moz-o13d22.bredband.telia.com) (Ping timeout: 121 seconds)
[03:32:20] *** Joins: c74d3 (c74d3a4ebb6@moz-0ersgu.oc.cox.net)
[03:34:08] *** Quits: c74d (c74d3a4ebb6@moz-3tkm7g.mggc.hibn.4404.2002.IP) (Ping timeout: 121 seconds)
[03:34:16] *** c74d3 is now known as c74d
[06:49:54] <Ilari> Hmm... 58 ciphersuites valid for TLS 1.3 (+ 5? from Chacha20 once added). 6 of those are TLS_DHE_DSS_WITH, which nobody uses, leaving 52 (+ chacha). With orthogonal negotiation and unified DH, those would need 16 codepoints total (+1 for Chacha20).
[06:53:31] <Ilari> And those 16 codepoints (assuming same matching between ciphers and hashes) would seeingly generate 90 old-style ciphersuites.
[06:53:57] <Ilari> Oops, 80.
[07:06:27] <Ilari> Seemingly ECDHE_PSK_ is missing (some devices might want that), as well as ECDH_anon (boo). CCM ciphers additionally don't have ECDHE_RSA nor DH_anon (boo).
[07:16:35] <Ilari> Apparently 6 from Chacha20, and adding that one missing kex would add 10 new, for total of 68. Orthogonal would need 17.
[09:31:04] *** Joins: irobevjodu (ident@moz-mikldi.static-ro.twistednetworks.net)
[11:41:53] *** Joins: Tobba (Tobba@moz-o13d22.bredband.telia.com)
[18:03:26] *** Joins: brson (brson@moz-jbs.7vl.56.172.IP)
[18:25:49] *** Quits: skeuomorf (skeuomorf@moz-d3l.n1e.32.197.IP) (Ping timeout: 121 seconds)
[18:26:11] *** Joins: skeuomorf (skeuomorf@moz-d3l.n1e.32.197.IP)
[18:43:09] *** Quits: skeuomorf (skeuomorf@moz-d3l.n1e.32.197.IP) (Ping timeout: 121 seconds)
[19:43:16] *** Quits: brson (brson@moz-jbs.7vl.56.172.IP) (Quit: leaving)
[20:10:05] *** Quits: coderanger (Noah@moz-m5ti9s.net) (Ping timeout: 121 seconds)
[20:14:09] *** Joins: coderanger (Noah@moz-m5ti9s.net)
[20:34:17] <bascule> ECC-hater guy thinks we should use Tiger instead of Blake2b to replace md5sum o_O
[20:34:58] <Tobba> what
[20:36:01] <bascule> I linked him this: http://link.springer.com/chapter/10.1007%2F978-3-540-76900-2_33
[20:36:53] <bascule> http://link.springer.com/chapter/10.1007%2F978-3-540-76900-2_33
[20:36:55] <bascule> err
[20:37:04] <bascule> http://www.metzdowd.com/pipermail/cryptography/2015-June/025800.html
[20:37:46] <Tobba> how is being slow in HW a plus
[20:38:36] <bascule> I don't know, it's certainly not a plus for NIST, heh
[20:38:43] <Tiffany> because the hardware accelerators will be rare, and therefore not be poisoned by the NSA, obviously
[20:40:23] <Tobba> obviously
[20:41:12] <Tiffany> it's weird to me that something can be slow in hardware
[20:41:15] <Tobba> it'd be pretty nice if we could have a single well-analyzed hash function instead of a billion ones
[20:41:22] <Tiffany> is that slow as in like
[20:41:28] <Tiffany> won't be a thousand times faster than software?
[20:41:36] <Tobba> Tiffany: some things when done in hardware end up just being a CPU with hardcoded instructions
[20:42:00] <Tiffany> what kind of things?
[20:42:08] <Tiffany> I imagine that you wouldn't want to duplicate the hardware used for computing rounds
[20:42:13] <Tiffany> so that would be some type of loop
[20:42:17] <Tiffany> but that's hardly a CPU
[20:42:42] <Tobba> tiger needs like 8 KB of memory
[20:42:45] <Tiffany> oh
[20:42:49] <Tobba> so you need to plumb all that crap around
[20:42:52] <Tiffany> I'm mainly thinking of AES and chacha
[20:43:14] <Tobba> oh uh
[20:43:21] <Tobba> chacha20 is "hard" because of the addition
[20:43:32] <Tiffany> yeah but like, what is hard about addition
[20:43:36] <Tobba> in software it doesn't matter, in HW all time will be spent doing the addition
[20:43:37] <Tiffany> just that you can't do it at 200 gigabytes per second?
[20:43:43] <Tobba> carries
[20:44:08] <Tiffany> what are the scales here?
[20:44:21] <Tiffany> like, it's obvious that you don't need an entire CPU to be able to implement chacha as fast as a CPU
[20:44:33] <Tobba> chacha in HW is obviously faster
[20:44:37] <Tiffany> okay
[20:44:42] <Tobba> it's just that if implemented in HW it'll be really crippled
[20:44:44] <Tiffany> but hardware chacha is slower than hardware AES, then?
[20:44:53] <Tiffany> how fast can hardware AES get?
[20:45:09] <Tiffany> my only references are the x86 instructions which are pretty slow, and some vague notion of accelerator chips
[20:45:11] <Tobba> if you look at things like SIMON, it only has binary operations and rotations
[20:45:42] <Tiffany> oh
[20:45:55] <Tiffany> but SIMON is slower in software because it needs more rounds?
[20:46:26] <Tobba> yeah
[20:46:39] <Tobba> in SW you won't notice a difference in speed from xor vs addition
[20:46:43] <Tobba> but in HW you will get fucked by ut
[20:46:46] <Tobba> it*
[20:46:58] <Tiffany> because hardware isn't limited by the time it takes to complete a cycle
[20:47:07] <Tiffany> and in terms of propagation delay, xor is much faster
[20:47:27] <Tiffany> so you end up with HW implementations that are either thousands of times faster, or take thousands of times less energy
[20:47:40] <Tobba> something like that
[20:48:15] <Tiffany> I wonder how fast chacha would actually be in hardware
[20:48:39] <Tobba> I think if you were serious about doing it in HW; each bit of addition would probably take one clock cycle
[20:48:49] <Tobba> and you'd have some crazy state machine to keep track of that, which obviously isn't ideal
[20:50:13] <Tiffany> why does it need to be tied to a clock cycle?
[20:51:01] <Tiffany> I figured you'd just have a pile of gates that corresponds to the round primitive, and maybe duplicate that a couple times to increase throughput, and then have some kind of clock and the 64-byte state as registers
[20:51:14] <Tobba> sorry, that didn't really make sense, uh
[20:51:22] <Tiffany> yeah I don't know that much about it
[20:51:24] <Tobba> non-constant-time addition
[20:51:28] <Tiffany> oh
[20:51:34] <Tobba> I don't do much in HW, so me neither really
[20:51:37] <Tiffany> is waiting for the worst case really that bad?
[20:51:58] <Tobba> worst-case is waiting for 64 full adders
[20:52:02] <Tiffany> that's like 32 + small n number of gates to propagate through
[20:52:08] <Tiffany> chacha only uses 32-bit words, not 64
[20:52:13] <Tobba> one round of simon is probably faster than a full adder in HW
[20:52:16] <Tobba> so yeah
[20:52:47] <Tiffany> I guess
[20:52:57] <Tobba> so just duplicate the simon round logic 32 times and bam
[20:53:10] <Tobba> you're now running one simon block in the time it takes to perform the addition in speck
[20:53:16] <Tiffany> 32 times if you have a key size of 64 bits
[20:53:39] <Tiffany> it looks like the reasonable security level is between 128 and 256 bits
[20:53:51] <Tiffany> er, between 68 and 72 rounds
[20:54:10] <Tobba> also ignore the thing I said about clocks and addition, you can't switch transistors that fast :P
[20:54:36] <Tiffany> I'm just kind of not sure what you would need this for
[20:55:14] <Tiffany> like, you have gate delay through how many transistors for a full block of simon? probably under a thousand
[20:55:23] <Tiffany> what do you need something that fast for?
[20:55:49] <Tiffany> even high end routers cap out at like 100 gbps
[20:56:20] <Tobba> simons gate delay would be uhh...
[20:56:25] <Tobba> 4 gates per round?
[20:56:35] <Tiffany> I see 5 dependent operations in the diagram
[20:56:39] <Tiffany> well no
[20:56:42] <Tobba> rotations are free
[20:56:43] <Tiffany> the rotate doesn't count
[20:56:49] <Tiffany> the & is one transistor
[20:56:53] <Tiffany> I don't know how many an xor takes
[20:56:54] <Tiffany> two?
[20:56:59] <Tobba> & should also take two I think
[20:57:03] <Tiffany> oh
[20:57:10] <Tobba> xor is more complicated, 8?
[20:57:21] <Tiffany> see, that's another thing I didn't know about hardware stuff
[20:57:28] <Tiffany> a transistor logically acts like an and gate
[20:57:35] <Tiffany> but in reality, you're usually feeding input voltage through one side
[20:57:45] <Tobba> I can't say I'm terribly educated either, but I've thought about that for a bit
[20:58:07] <Tiffany> the fun thing is how logically transistors aren't even a complete base
[20:58:15] <Tiffany> not gates depend on resistence to work
[20:58:27] <Tobba> I'd guess you can use them like an AND gate, but only sometimes
[20:58:39] <Tobba> i.e if you have enough juice to drive it
[20:58:52] <Tiffany> so for an xor
[20:59:50] <Tiffany> I've built these in minecraft before
[21:00:00] <Tobba> (A | B) & !(A & B)
[21:00:14] <Tiffany> yeah
[21:00:24] <Tiffany> how do you implement an OR in gates?
[21:00:29] <Tobba> OR gate should essentially just be 1 transistor (prevent backflow), then an AND gate that's set up to short it out
[21:00:31] <Tiffany> in minecraft you would just merge the lines together..
[21:00:48] <Tobba> well, 1 transistor per input
[21:01:13] <Tobba> so AND would be 1-2 transistors, XOR would be 2-3?
[21:01:33] <Tobba> err
[21:01:50] <Tobba> XOR would be 4-5*
[21:02:21] <Tobba> in terms of gate delay, 1-2 and 2-3?
[21:02:25] <Tiffany> apparently xor in CMOS requires 12 transistors
[21:02:31] <Tiffany> or 8
[21:02:43] <cmr> You can do NAND, NOR, and NOT in 2 CMOS transistors per input, AND and OR in 2 per input plus 2.
[21:03:15] <Tobba> yeah it also obviously depends on what gates you're using
[21:03:34] <Tobba> but uh, it's still only like 20 gates worth of delay per round?
[21:03:45] <Tobba> so it really just depends on what kind of clock rates you can drive your transistors at
[21:03:46] <Tiffany> http://cdn.instructables.com/F21/AWXG/GVO9FOT6/F21AWXGGVO9FOT6.LARGE.jpg
[21:05:53] <Tiffany> so if you can switch your transistors a billion times a second
[21:06:06] <Tiffany> at 20 gates delay, with 72 rounds at 128-bit block size with 256-bit key
[21:06:09] <Tiffany> that's 460 gigabits per second
[21:06:38] <Tiffany> well, assuming you wait for the whole round to finish before starting a new one
[21:06:55] <Tobba> gate delay and switching speed aren't necessarily the same
[21:06:59] <Tiffany> is simon random access?
[21:07:41] <Tiffany> well, block, not round
[21:07:45] <Tobba> I'd guess you'd be bound purely by how fast you can switch the transistors
[21:08:15] <Tiffany> oh, it's a block cipher
[21:09:04] <Tiffany> if you duplicate the gates to perform multiple rounds, and do one round at a time instead of one block at a time
[21:09:23] <Tiffany> ah
[21:09:24] <Tiffany> crap
[21:09:28] <Tiffany> I made a mistake
[21:09:30] *** Joins: brson (brson@moz-cfhap5.mtv2.mozilla.com)
[21:09:37] <Tobba> well, I'd assume you're completely bounded by how fast you can feed the chip data
[21:09:54] <Tiffany> units does that thing where both * and / have equal precedence
[21:10:03] <Tiffany> so A / B*C is actually (A/B)*C
[21:10:59] <Tiffany> so if you do a block at a time, at a billion gate switches per second, and it takes 20 gate switches to finish a round, then you get .. 88 megabits/second? that doesn't sound right
[21:11:34] <Tobba> gate switching time doesn't have much to do with gate delay
[21:11:39] <Tiffany> you said as much
[21:11:44] <Tiffany> but I don't know how else to calculate this
[21:12:14] <Tobba> I'd assume if you could switch them 1 billion times per second, you might be able to do 1 billion blocks per second
[21:12:22] <Tobba> but you probably can't actually switch them that fast
[21:12:54] <Tiffany> only if you feed in blocks at the rate each transistor can switch, yeah
[21:13:12] <Tiffany> and the timings are all perfect
[21:13:30] <Tiffany> you'd need nop transistors to keep everything lined up, probably
[21:13:43] <Tobba> yeah uh
[21:13:50] <Tobba> actually, 1 GHz does seem feasible just with how simple it is
[21:13:57] <Tobba> but there's a key expansion thing as well, so I'm not entirely sure
[21:14:25] <Tiffany> a billion blocks per second would be 16 gigabytes per second which is 128 gigabits per second
[21:15:04] <Tiffany> that's not quite as stupidly fast as I was thinking
[21:15:47] <Tiffany> chacha on haswell is about 7 gigabits per second
[21:16:23] <Tiffany> and I think that's while SIMD is in use, so you'd get less effective throughput if your messages were under 128 bytes long
[21:16:28] <Tiffany> er
[21:16:37] <Tobba> Tiffany: according to wikipedia, 10ns/switch
[21:16:49] <Tiffany> that's interesting
[21:17:01] <Tobba> which is only 100Mhz, interesting indeed
[21:17:20] <Tobba> (for a 90nm CMOS ASIC)
[21:17:29] <Tiffany> oh
[21:18:37] <Tobba> ... that doesn't seem right, really, hold on
[21:19:01] <Tobba> oh, 120ps switch time, and 10ns between switches, seems about right
[21:19:05] <Tiffany> oh
[21:19:06] <Tobba> what else is there than CMOS?
[21:19:27] <Tobba> if each block depends on the previous ones, you might actually get hit by the gate delay
[21:19:33] <Tiffany> so that'd be 12.8 gigabits per second if you could do a block every time you can switch
[21:19:48] <Tiffany> and the latency would be very low
[21:20:10] <Tiffany> MOSFET?
[21:20:17] <Tiffany> those are used in CPUs iirc
[21:20:53] <Tiffany> you'd better hope that if you're trying to do really fast crypto that you're using counter mode
[21:24:38] <Tiffany> I think I might be fangirling over hash functions in counter mode such as chacha too much
[21:25:23] <Tobba> I'd assume those numbers are for cheaper ASICs
[21:25:31] <Tobba> so 12.8 gigabits per second is pretty good
[21:25:53] <Tobba> though you may also have to include the key expansion step, need to read the paper
[21:26:12] <Tiffany> I should read about block ciphers some more
[21:26:20] <Tiffany> are there any really simple ones that I can go read about?
[21:26:53] <Tiffany> preferably one which has good documentation
[21:27:03] <cmr> DES? ;)
[21:27:55] <Tiffany> DES looks kind of complicated actually
[21:28:03] <Tiffany> I don't know anything about feistel networks
[21:29:00] <Tiffany> TEA looks like it might be a good introduction to block ciphers
[21:29:43] <cmr> TEA is a feistel cipher too
[21:29:48] <Tiffany> apparently
[21:30:01] <Tobba> simon's key expansion pseudocode is a bit weird to read, but you can use pre-expanded keys or something
[21:30:02] <Tiffany> I saw that diagram on the DES page and it looked intimidating
[21:30:06] <cmr> feistel ciphers are a pretty common construction that's worth learning.
[21:30:13] <Tiffany> and it described it as a feistel function
[21:39:34] <Tobba> I like how modern ciphers seem to be less complicated than the old ones
[21:39:52] <Tobba> AES is a complete clusterfuck with tons of steps per round and some messy S-box for key expansion
[21:40:04] <Tobba> I'm pretty sure I could keep chacha in my head
[21:46:07] <Tobba> Tiffany: heh, I think I actually learned a lot about ASICs from trying to figure out how a Simon ASIC would work
[21:51:20] <eternaleye> Tobba: Well, 90nm is kind of low-spec these days too, IIRC. TSMC can get you 45nm, and Intel is working at 22nm as a matter of course.
[21:52:15] <Tobba> eternaleye: neat, though if my (incorrect) calculations are right, you wouldn't need more than 90nm
[21:52:56] <Tobba> assuming the other parts of the chip can feed the cipher part data fast enough, it shouldn't be possible to really saturate it with useful data
[21:53:09] <eternaleye> Tobba: Actually, I think RISC-V actually did an experimental tapeout at 45nm of an earlier version...
[21:53:32] <eternaleye> Tobba: So you can definitely go to someone like TSMC and say "Hey, I want X copies of this in 45nm"
[21:53:49] <Tobba> sure
[21:54:43] <Tobba> but you should have a hard time saturating 12 Gbps
[21:54:57] <Tobba> OTOH, the interface to the CPU will probably bottleneck it, depending on how it's set up
[21:59:06] <eternaleye> Tobba: No, I mean that if the RISC-V folks can walk up to TSMC and do it, other groups can
[21:59:13] <eternaleye> Tobba: Not that RISC-V solves this issue
[21:59:41] <eternaleye> Tobba: Also, RISC-V's coprocessor and/or custom instruction encoding space would work pretty well there.
[22:00:23] <eternaleye> Tobba: Implemented as a coprocessor in the messaging paradigm, you'd send it a pointer and a length for it to process, and then be able to fence on completion
[22:01:08] <eternaleye> Tobba: Implemented as an instruction, you'd probably do something more like AES-NI (though as it doesn't do SIMD, a place to _put_ the data might be an issue)
[22:03:49] <Tobba> eternaleye: I never said that
[22:04:03] <Tobba> eternaleye: I meant there's no point in going to 45nm
[22:04:08] <eternaleye> Ah
[22:04:19] <eternaleye> Tobba: Well, I do disagree there
[22:04:35] <eternaleye> Tobba: Case in point, depending on the CPU interface, you can get parallelism between blocks
[22:04:50] <Tobba> or may not be any, anyways, what I meant was that the interface to the CPU might not be able to do the 12 Gbps the crypto can do
[22:04:52] <eternaleye> Tobba: The coprocessor one in particular
[22:05:27] <eternaleye> Tobba: If the len covers multiple blocks, you can scale up to (len/blocksize)x speed so long as you spend the area
[22:06:17] <Tobba> true (assuming the memory can go that fast)
[22:09:48] *** Quits: brson (brson@moz-cfhap5.mtv2.mozilla.com) (Quit: leaving)
[22:10:42] <eternaleye> Tobba: Well, a cacheline (512 bits) is exactly what Chacha operates on, and IIRC most CPUS can do... what, 3 cacheline fetches at once? 4?
[22:11:51] <eternaleye> Tobba: Then if each block takes any more than a clock cycle, you can actually multiply that by how many clock cycles it takes, and interleave by pipelining.
[22:12:05] <eternaleye> Tobba: So the _speed_ becomes 1/cycle, even if the _latency_ is higher.
[22:12:40] <Tiffany> I don't think AES-NI style extensions for chacha would be worth it
[22:12:45] <Tiffany> unless you did an entire block as a single instruction
[22:12:48] <eternaleye> Tiffany: Agreed
[22:13:08] <eternaleye> Tiffany: Stream ciphers can take advantage of pointer-len style APIs much more easily
[22:13:21] <eternaleye> Tiffany: Whereas with block ciphers, you'd need such a thing _per mode_
[22:13:43] <eternaleye> Tiffany: And ctr mode would be the most beneficial to do that way, - i.e., make it a stream cipher
[22:13:47] <Tiffany> who said anything about doing block cipher -> stream cipher in hardware?
[22:14:17] <eternaleye> Tiffany: Chacha, as a stream cipher, can use an API that works like "Hey, encrypt this buffer" much more easily.
[22:14:33] <Tiffany> oh, APIs
[22:14:41] <eternaleye> Tiffany: Block ciphers, which need modes, have much more hardware complexity if you use the same kind of API
[22:14:51] <eternaleye> Tiffany: Since then you need to do the mode "under the hood"
[22:15:01] <Tiffany> chacha is pretty much a hash function in counter mode though
[22:15:15] <eternaleye> Tiffany: So a coprocessor approach (instead of an AES-NI approach) works better for stream ciphers than block ciphers
[22:15:29] <eternaleye> Tiffany: Reducing the benefit of AES-NI style hardware support
[22:16:11] <eternaleye> Tiffany: (Also, Chacha on big SIMD _is_ basically "AES-NI for Chacha")
[22:16:34] <Tiffany> except that wide SIMD assumes that your messages are long enough to actually need multiple blocks of keystream
[22:16:37] <eternaleye> Tiffany: The main reason AES-NI had to be a thing, IMO, is the S-boxes
[22:16:55] <eternaleye> Tiffany: Er, no, I mean using wide simd to do one block of Chacha in a single register
[22:16:55] <Tiffany> yeah, that makes sense
[22:17:03] <eternaleye> Tiffany: Not bitslicing
[22:17:09] <Tiffany> oh
[22:17:37] <eternaleye> See also: AVX-512
[22:19:46] <Tiffany> .. huh
[22:19:53] <Tiffany> I didn't realize 512 bits was 64 bytes
[22:19:58] <Tiffany> that's pretty interesting
[22:19:59] <eternaleye> Yup
[22:20:10] <Tiffany> you can use the masking instructions in AVX-512 to operate only on parts of the register, right?
[22:20:12] <eternaleye> I suspect AVX won't go past 512, though
[22:20:23] <eternaleye> Since beyond that you start spanning multiple cachelines
[22:20:28] <eternaleye> Tiffany: I think so
[22:20:43] <Tiffany> and well also AVX-512 has 2 kilobytes worth of registers
[22:20:53] <eternaleye> Yup
[22:21:07] <Tobba> chacha extension with AVX-512 could also have "create a block and put it in this register", couldn't it?
[22:21:17] <Tiffany> I wonder if they'll start adding tons of compound operators or something instead of expanding horizontally
[22:21:19] <eternaleye> Tobba: Mm, probably
[22:21:58] <Tiffany> I expect a chacha extension would be in the form of accelerator instructions for AVX-512
[22:22:00] <eternaleye> Tobba: Though considering x86, I wouldn't do that
[22:22:12] <Tobba> probably not, it'd just be sorta neat
[22:22:15] <eternaleye> Tobba: I'd do "create a block and xor it with this register"
[22:22:29] <eternaleye> Tobba: Then you can just use a zeroed register if you want something fancy
[22:22:43] <eternaleye> Tobba: Or directly encrypt message blocks if not
[22:23:31] *** Quits: eddyb (eddyb@moz-2fd.hlc.26.188.IP) (Ping timeout: 121 seconds)
[22:24:28] <Tiffany> I wonder if that thing that lets you define arbitrary bit-wise operators with 3 inputs using an 8-bit truth table
[22:24:36] <Tiffany> could make ciphers faster
[22:24:42] <Tiffany> probably simon
[22:24:57] <Tobba> probably AES
[22:25:01] <Tiffany> yeah
[22:25:12] <Tiffany> the & and 3 xors could be decomposed into two of those tables
[22:25:28] <Tobba> oh yeah, that'd be cool
[22:25:32] <Tiffany> build a truth table of (A&B)^C and A^B^C and bam
[22:25:37] <Tobba> you could do a round of simon in 1 instruction with that
[22:25:47] <Tiffany> uh
[22:25:49] <Tiffany> 1 instruction?
[22:25:52] <Tobba> or wait, no
[22:26:11] <Tobba> three instructions
[22:26:19] <Tiffany> I think it'd be more than that
[22:26:28] <Tiffany> there'd be 3 rotates, and then two truth tables
[22:27:13] <Tiffany> so that'd be like 5 instructions?
[22:27:28] <Tiffany> there might be some other data shuffling that has to be done
[22:27:29] <Tobba> you could roll the 3 rotates, AND and XOR into a lookup table
[22:27:38] <Tobba> then you just XOR it all together
[22:27:43] <Tiffany> er
[22:27:46] <Tiffany> not with this instruction
[22:27:53] <Tiffany> it's bit-wise, you can't do rotates
[22:28:33] <Tiffany> you could roll it into 3 rotates and 1 lookup if you could have 6 inputs instead of just 3
[22:28:41] <Tobba> oh, uh
[22:28:43] <Tiffany> but then you'd need a 64-bit truth table instead of an 8-bit one
[22:28:55] <Tobba> could still use it for 3-way XOR
[22:28:58] <Tiffany> yeah
[22:29:15] <Tiffany> (A&B)^C and A^B^C used in simon can both be done in one instruction
[22:29:21] <Tobba> there might be some SSE-way of doing lookup tables
[22:29:23] <Tiffany> and 3-way xor is useful in more than just simon
[22:31:50] <Tiffany> I don't remember if there's any in chacha
[22:32:12] <Tiffany> I think djb avoided them
[22:32:26] <Tiffany> there might be some 3-way adds, since lea instruction
[22:32:29] <Tobba> chacha is xor and addition I think?
[22:32:37] <Tiffany> xor, addition, and rotate left by constant
[22:32:41] <Tobba> where this doesn't really help
[22:40:33] <Tobba> seriously though, why is AES so complicated?
[22:41:41] <Tiffany> I actually don't know how AES works
[22:41:57] *** Quits: irobevjodu (ident@moz-mikldi.static-ro.twistednetworks.net) (Ping timeout: 121 seconds)
[22:44:46] <Tiffany> wait
[22:44:54] <Tiffany> AES's S-box is only 8 bits?
[22:46:22] <Tiffany> I got the impression it was large
[22:46:30] <Tiffany> because of everyone mentioning timing attacks
[22:48:02] <Tiffany> maybe they use a larger lookup table so they don't have to do bit twiddling
[22:48:55] <Tiffany> oh
[22:49:06] <Tiffany> it's 8 bits of address, not 8 bits of data
[22:49:16] <Tiffany> 256 bytes is still only 4 cache lines though
[22:49:37] <Tiffany> I find it hard to imagine you could build an effective timing attack against this
[22:51:15] <Tiffany> djb did a timing attack with 200 million chosen plaintexts with precise cycle timing analysis
[22:51:18] <Tiffany> how does that even work?
[22:51:25] <Tiffany> the S-box should never leave cache
[22:52:54] <Tiffany> wikipedia mentions "compression tables" but does not define the term
[22:54:20] <Tiffany> it links a paper which is flying over my head
[22:56:43] <Tiffany> I don't have any idea what compressed tables are
[22:56:49] <Tiffany> but apparently they can be 1 or 2 kilobytes
[22:56:55] <Tiffany> and that's where the timing attacks come frmo
[23:23:29] *** Joins: irobevjodu (ident@moz-3vi4l0.static-ro.twistednetworks.net)
